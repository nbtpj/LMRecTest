{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ! git clone https://github.com/nbtpj/LMRecTest.git\n","# import os\n","# os.chdir('LMRecTest/')\n","# ! ls\n","# !mkdir ./cache/\n","# !cp -R /kaggle/input/lmrec-data/* ./cache/\n","# !rm -r cache/sampled_prompt_movilens_dataset.hf\n","# !ls cache"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["!python make_data.py 4000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from env_config import TERM_TO_ESTIMATE, RATINGS, movielen_feat_map\n","\n","test_scenario = {\n","    'biography only': ['bio prompt'],\n","    'bio + top 10 nearest ratings': ['bio prompt', 'history prompt'],\n","    'bio + 10 nearest ratings + history overview': ['bio prompt', 'history prompt', 'history overview prompt'],\n","    'bio + 10 nearest ratings + history overview + age-group': ['bio prompt', 'history prompt', 'history overview prompt', 'age-group prompt'],\n","    'bio + 10 nearest ratings + history overview + age-group + next-category': ['bio prompt', 'history prompt', 'history overview prompt', 'age-group prompt', 'cross-cate prompt'],\n","}\n","\n","def film_promt(film_meta: dict) -> dict:\n","    title = None\n","    try:\n","        title = film_meta['movie_title'].decode('utf-8')\n","    except:\n","        pass\n","    categories = []\n","    try:\n","        categories = [movielen_feat_map['movie_genres'][k] for k in film_meta['movie_genres']]\n","    except:\n","        pass\n","\n","    return {\n","        'target prompt': f'The movie named {title} is categorized as {\", \".join(categories)}.{TERM_TO_ESTIMATE}'\n","    }\n","\n","def map2ctx(rating, test_scenario, targets_ids):\n","    r = {}\n","    for name, cols_to_gather in test_scenario.items():\n","        try:\n","            r[name] = [rating[col] for col in cols_to_gather]\n","            r[name] = ' '.join(r[name])\n","        except:\n","            pass\n","    r.update({\n","        'user_rating': rating['user_rating'],\n","        'expected': targets_ids.index(rating['movie_id'])\n","    })\n","    return r"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["RATINGS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from env_config import device\n","import torch\n","from torch import nn"]},{"cell_type":"markdown","metadata":{},"source":["# Test Recommender Scenario\n","___"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from BARTRec import rank_with_bart\n","from GPTRec import rank_with_gpt\n","from datasets import load_from_disk\n","import numpy as np\n","\n","    \n","unified_dataset = load_from_disk('cache/datasets.hf')\n","sampled_prompt_movilens_dataset = load_from_disk('cache/sampled_prompt_movilens_dataset.hf')\n","# target_details = unified_dataset['movielens-1m-movies'].map(film_promt)\n","target_details = sampled_prompt_movilens_dataset.map(film_promt)\n","\n","\n","targets = target_details['target prompt'] # all possible selections\n","targets_ids = target_details['movie_id']\n","\n","\n","context_selection = sampled_prompt_movilens_dataset.map(map2ctx, \n","                                                        fn_kwargs = {'test_scenario':test_scenario, 'targets_ids': targets_ids},\n","                                                        remove_columns=sampled_prompt_movilens_dataset.column_names)\n","expected = np.array(context_selection['expected'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["context_selection"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import BartTokenizer, BartForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel\n","from metrics import *\n","from tqdm import tqdm\n","\n","available_selections = target_details['target prompt']\n","rank_method_names = ['BART', 'GPT']\n","rank_methods = [rank_with_bart, rank_with_gpt]\n","models = [BartForConditionalGeneration.from_pretrained('facebook/bart-base').to(device), GPT2LMHeadModel.from_pretrained('gpt2').to(device)]\n","if torch.cuda.device_count() > 1:\n","  for i in range(len(models)):\n","    models[i] = nn.DataParallel(models[i])\n","tokenizers = [BartTokenizer.from_pretrained('facebook/bart-base'), GPT2Tokenizer.from_pretrained('gpt2')]\n","tokenizers[-1].add_special_tokens({'pad_token': '[PAD]'})\n","size = 20\n","results = []\n","for scenario in tqdm(test_scenario):\n","    if scenario in context_selection.column_names:\n","        contexts = context_selection[scenario]\n","        for rank_method, model, tokenizer, name in zip(rank_methods, models, tokenizers, rank_method_names):\n","            predictions = rank_method(model=model, tokenizer=tokenizer,\n","                                contexts=contexts, available_selections=available_selections,\n","                                term_to_estimate = TERM_TO_ESTIMATE)\n","            eval_rs = MMRandR(predictions, expected, size=20)\n","            results.append({'model': name, 'scenario': scenario, **eval_rs})\n","len(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","df = pd.DataFrame(results)\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# Test Rating-prediction Scenario\n","___"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from BARTRec import rank_with_bart\n","from GPTRec import rank_with_gpt\n","from datasets import load_from_disk\n","import numpy as np\n","\n","    \n","unified_dataset = load_from_disk('cache/datasets.hf')\n","sampled_prompt_movilens_dataset = load_from_disk('cache/sampled_prompt_movilens_dataset.hf')\n","target_details = unified_dataset['movielens-1m-movies'].map(film_promt)\n","\n","targets = target_details['target prompt'] # all possible selections\n","targets_ids = target_details['movie_id']\n","\n","\n","context_selection = sampled_prompt_movilens_dataset.map(map2ctx, \n","                                                        fn_kwargs = {'test_scenario':test_scenario, 'targets_ids': targets_ids},\n","                                                        remove_columns=sampled_prompt_movilens_dataset.column_names)\n","expected = np.array(context_selection['user_rating'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import BartTokenizer, BartForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel\n","from metrics import *\n","from tqdm import tqdm\n","\n","available_selections = RATINGS\n","rank_method_names = ['BART', 'GPT']\n","rank_methods = [rank_with_bart, rank_with_gpt]\n","models = [BartForConditionalGeneration.from_pretrained('facebook/bart-base').to(device), GPT2LMHeadModel.from_pretrained('gpt2').to(device)]\n","if torch.cuda.device_count() > 1:\n","  for i in range(len(models)):\n","    models[i] = nn.DataParallel(models[i])\n","tokenizers = [BartTokenizer.from_pretrained('facebook/bart-base'), GPT2Tokenizer.from_pretrained('gpt2')]\n","tokenizers[-1].add_special_tokens({'pad_token': '[PAD]'})\n","\n","size = 20\n","results = []\n","for scenario in tqdm(test_scenario):\n","    if scenario in context_selection.column_names:\n","        contexts = context_selection[scenario]\n","        for rank_method, model, tokenizer, name in zip(rank_methods, models, tokenizers, rank_method_names):\n","            predictions = rank_method(model=model, tokenizer=tokenizer,\n","                                contexts=contexts, available_selections=available_selections,\n","                                term_to_estimate = TERM_TO_ESTIMATE)\n","            predictions = predictions[..., 0] + 1 # convert from index to rating\n","            eval_rs = rmse(predictions, expected)\n","            results.append({'model': name, 'scenario': scenario, **eval_rs})\n","len(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","df = pd.DataFrame(results)\n","df"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
